{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45782dda",
   "metadata": {},
   "source": [
    "# Введение в PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd18d090",
   "metadata": {},
   "source": [
    "PyTorch Lightning — это лёгкая надстройка над **PyTorch**, которая упрощает\n",
    "рутинный код обучения нейронных сетей и делает проекты чище и повторно‑используемыми.\n",
    "\n",
    "> **Кому адресовано:** этот ноутбук рассчитан на первокурсников, которые уже знакомы\n",
    "с базовым синтаксисом Python и минимально — с PyTorch, но ещё не уверенно\n",
    "ориентируются в деталях обучения моделей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9a2d9",
   "metadata": {},
   "source": [
    "## Зачем нужен PyTorch Lightning?\n",
    "\n",
    "*  **Отделение модели от тренировки.** Вся логика обучения (оптимизация,\n",
    "  логирование, сохранение checkpoints) выносится из реализации модели.\n",
    "*  **Меньше «боулерплейта».** Не нужно вручную писать циклы по эпохам,\n",
    "  вычисление метрик и т.д.\n",
    "*  **Воспроизводимость.** Параметры тренировки и структура проекта\n",
    "  стандартизированы.\n",
    "*  **Инфраструктура “из коробки”.** Лёгкий переход на multi‑GPU, TPU, AMP,\n",
    "  16‑bit/8‑bit precision — без изменения кода модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb0236",
   "metadata": {},
   "source": [
    "## Ключевые понятия\n",
    "\n",
    "| Термин | Роль |\n",
    "|--------|------|\n",
    "| **`LightningModule`** | Класс, куда вы помещаете слои модели и определяете `forward`, `training_step`, `validation_step`, `configure_optimizers` |\n",
    "| **`Trainer`** | Объект, который берёт `LightningModule` и проводит обучение / валидацию / тест |\n",
    "| **`LightningDataModule`** | (Необязательно) инкапсулирует загрузку и препроцессинг данных |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3252144",
   "metadata": {},
   "source": [
    "## Установка\n",
    "\n",
    "```bash\n",
    "pip install pytorch-lightning torch torchvision\n",
    "```\n",
    "\n",
    "> ⚠️ Установка внутри ноутбука может занять пару минут.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aaad7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e6d61",
   "metadata": {},
   "source": [
    "## Полное сравнение: «чистый» PyTorch vs PyTorch Lightning\n",
    "\n",
    "Ниже два сниппета выполняют **одну и ту же задачу** — обучают простую\n",
    "CNN на MNIST.\n",
    "\n",
    "*В варианте PyTorch* мы явно описываем модель и вручную реализуем цикл по\n",
    "батчам: обнуляем градиенты, считаем лосс, делаем шаг оптимизатора, выводим\n",
    "метрики.\n",
    "\n",
    "*В варианте Lightning* вся та же логика умещается в методы `LightningModule`,\n",
    "а цикл обучения берёт на себя `Trainer`.\n",
    "\n",
    "*Для наглядности рекомендуется скрыть класс моделей в обеих ячейках*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] train_loss=0.2322 | val_loss=0.0674 | val_acc=97.88%\n",
      "  → New best model saved (acc=97.88%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/3] train_loss=0.0682 | val_loss=0.0456 | val_acc=98.39%\n",
      "  → New best model saved (acc=98.39%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/3] train_loss=0.0467 | val_loss=0.0434 | val_acc=98.67%\n",
      "  → New best model saved (acc=98.67%)\n",
      "Обучение завершено.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# === «Чистый» PyTorch ===\n",
    "class PTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Слои сверток (Экстрактор фичей)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        # Полносвязная \"голова\" (Классификатор)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 12 * 12, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Гиперпараметры и подготовка данных\n",
    "lr              = 1e-4\n",
    "weight_decay    = 1e-2\n",
    "batch_size      = 32\n",
    "num_epochs      = 3\n",
    "device          = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "train_ds = MNIST(root='data', train=True, download=True, transform=transform)\n",
    "val_ds   = MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds, batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "# Инициализация\n",
    "model_pt = PTModel().to(device)\n",
    "optimizer = torch.optim.AdamW(model_pt.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Обучение\n",
    "    model_pt.train()\n",
    "    train_loss = 0.0\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} – train\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model_pt(x)\n",
    "        loss   = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Валидация\n",
    "    model_pt.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(val_loader, desc=\"valid\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model_pt(x)\n",
    "            loss   = loss_fn(logits, y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds   = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc   = correct / total\n",
    "\n",
    "    # Лог\n",
    "    print(f\"[{epoch}/{num_epochs}] \"\n",
    "          f\"train_loss={train_loss:.4f} | \"\n",
    "          f\"val_loss={val_loss:.4f} | \"\n",
    "          f\"val_acc={val_acc:.2%}\")\n",
    "\n",
    "    # Сохранение лучшей модели\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model_pt.state_dict(), \"best_model.pt\")\n",
    "        print(f\"  → New best model saved (acc={best_acc:.2%})\")\n",
    "\n",
    "print(\"Обучение завершено.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bda24b",
   "metadata": {},
   "source": [
    "## Та же самая логика c PyTorch Lightning\n",
    "\n",
    "Обратите внимание, что мы **не пишем** цикл по батчам/эпохам — за нас это\n",
    "делает `Trainer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0dd9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type               | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | conv    | Sequential         | 18.8 K | train\n",
      "1 | fc      | Sequential         | 1.2 M  | train\n",
      "2 | loss_fn | CrossEntropyLoss   | 0      | train\n",
      "3 | val_acc | MulticlassAccuracy | 0      | train\n",
      "-------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.800     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d33067ee8f4142a05ad8b2261885b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da728c6dd0349809826d8772d1f55c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c232268813794490a6880df84aa6a85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f735c36b8649719bd3559d9a127e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50705cab6ac04c90953ce510d6d607a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# === PyTorch Lightning ===\n",
    "class LitMNIST(pl.LightningModule):\n",
    "    def __init__(self, lr: float = 1e-3, weight_decay: float = 1e-2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()  # сохраняем гиперпараметры\n",
    "        \n",
    "        # Слои сверток (Экстрактор фичей)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "        # Полносвязная \"голова\" (Классификатор)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 12 * 12, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "        # Функция потерь\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Метрика\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)     # Получаем предсказанные классы\n",
    "        acc = self.val_acc(preds, y)\n",
    "\n",
    "        # prog_bar=True выводит метрики в прогресс-баре Trainer-а. Note: недоступно в ipynb\n",
    "        self.log(\"val_loss\", loss, prog_bar=False, on_epoch=True, on_step=False)\n",
    "        self.log(\"val_acc\", acc,  prog_bar=False, on_epoch=True, on_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "        return optimizer\n",
    "    \n",
    "# Датасет и DataLoader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "mnist_train = MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "mnist_val   = MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(mnist_val,   batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "# Инициализация модели и тренера\n",
    "model = LitMNIST(lr=1e-4, weight_decay=1e-2)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=3, \n",
    "    accelerator=\"gpu\",  \n",
    "    devices=1,                  # Выбираем кол-во видеокарт\n",
    "    # strategy=\"ddp\",           # Если реально несколько GPU и доступна DDP. Note: DDP недоступна в ipynb\n",
    "    log_every_n_steps=50,\n",
    ")\n",
    "\n",
    "# Обучение\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88717148",
   "metadata": {},
   "source": [
    "## Логирование и мониторинг: TensorBoard и Weights & Biases\n",
    "\n",
    "PyTorch Lightning поддерживает популярные системы отслеживания экспериментов\n",
    "«из коробки». Достаточно передать объект‑логгер в `Trainer`. Метрики,\n",
    "графики лосса и другие параметры будут автоматически\n",
    "отправляться в выбранный backend.\n",
    "\n",
    "* **TensorBoard** — локальный веб‑интерфейс, входящий в состав PyTorch.\n",
    "* **Weights & Biases (wandb)** — облачный сервис, удобный для коллаборации.\n",
    "\n",
    "```python\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "# TensorBoard (метрики сохранятся в ./tb_logs/)\n",
    "tb_logger = TensorBoardLogger(\"tb_logs\", name=\"mnist\")\n",
    "\n",
    "# wandb (сначала `pip install wandb`)\n",
    "# wb_logger = WandbLogger(project=\"mnist-demo\")\n",
    "```\n",
    "\n",
    "> 💡 Если wandb не установлен, Python пропустит создание `WandbLogger`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb0a2f",
   "metadata": {},
   "source": [
    "### Запуск TensorBoard после начала обучения\n",
    "\n",
    "> **Важно:** по умолчанию `pytorch_lightning` сохраняет логи в папку `lightning_logs/`.\n",
    "\n",
    "1. **Внутри ноутбука**  \n",
    "   ```python\n",
    "   %load_ext tensorboard\n",
    "   %tensorboard --logdir lightning_logs/ --port 6006\n",
    "   ```\n",
    "   После выполнения под ячейкой появится интерфейс TensorBoard и графики будут обновляться в режиме реального времени.\n",
    "\n",
    "2. **Через терминал**  \n",
    "   Откройте терминал в папке с ноутбуком и выполните:  \n",
    "   ```bash\n",
    "   tensorboard --logdir lightning_logs/ --port 6006\n",
    "   ```\n",
    "   Затем перейдите в браузере по адресу <http://localhost:6006>.\n",
    "\n",
    "3. **Если обучение идёт на удалённом сервере**  \n",
    "   Пробросьте порт:\n",
    "   ```bash\n",
    "   ssh -L 6006:localhost:6006 user@remote-server\n",
    "   ```\n",
    "   После этого откройте `http://localhost:6006` в своём браузере.\n",
    "\n",
    "> **Советы**  \n",
    "> * Меняйте номер порта (`--port 6007`), если 6006 уже занят.  \n",
    "> * Для сравнения экспериментов сохраняйте логи в разные подпапки, например `run1/`, `run2/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602285d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type               | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | conv    | Sequential         | 18.8 K | train\n",
      "1 | fc      | Sequential         | 1.2 M  | train\n",
      "2 | loss_fn | CrossEntropyLoss   | 0      | train\n",
      "3 | val_acc | MulticlassAccuracy | 0      | train\n",
      "-------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.800     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd51acc7df44f7fb76069fb75043c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f3d1669643469ba965d44d3931520b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a98dc8be3ba4a6498bd860bc30099e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c77c7d9a5442278c57d6563dcaed5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757b01b3e4064460a95604e2a309432a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "# from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "tb_logger = TensorBoardLogger(\"tb_logs\", name=\"mnist\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    # strategy=\"ddp\",\n",
    "    logger=tb_logger,   # Передаем объект логгера: 'logger=tb_logger'\n",
    "    log_every_n_steps=50\n",
    ")\n",
    "\n",
    "# Обучение\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbc326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20004), started 0:03:39 ago. (Use '!kill 20004' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-150a16ec80994eea\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-150a16ec80994eea\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/ --port 6006\n",
    "# Далее открываем localhost:6006 в своем браузере. Note: VPN может мешать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2dbc8",
   "metadata": {},
   "source": [
    "## Когда применять Lightning?\n",
    "\n",
    "* **Учебные и исследовательские проекты.** Сфокусируйтесь на идеях, а не\n",
    "  на вспомогательном коде.\n",
    "* **Командная разработка.** Стандартизированная структура облегчает ревью и\n",
    "  переиспользование.\n",
    "* **Прототипы с возможностью масштабирования.** Когда понадобится\n",
    "  распределённое обучение — код уже готов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a9acc9",
   "metadata": {},
   "source": [
    "## Полезные ссылки\n",
    "\n",
    "* **Обязательно к изучению:** <https://lightning.ai/docs/pytorch/stable/starter/introduction.html>\n",
    "* Документация: <https://lightning.ai/docs/pytorch/latest/>\n",
    "* Шорт‑гайды: <https://lightning.ai/docs/pytorch/stable/tutorials.html>\n",
    "* GitHub: <https://github.com/Lightning-AI/pytorch-lightning>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db53c8e6",
   "metadata": {},
   "source": [
    "## P.S.\n",
    "* Made by REU DS Club\n",
    "* По всем вопросам в tg: @yoursAnthony\n",
    "## Links (REU DS Club):\n",
    "* vk: https://vk.com/reu_ds_club\n",
    "* tg: https://t.me/+pkbsRGH1Bt030DNi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
